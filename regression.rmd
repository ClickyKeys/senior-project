---
output: html_document
---

# Predicting Hospital Quality Using Hospital Characteristic Data

The aim of this analysis is to determine if hospital star ratings can be predicted using several hospital characteristic-related variables.  To achieve this, ordinal logistic regression was used to model the relationship between star ratings (the ordinal response variable) and hospital characteristics (the explanatory variables).  The 80/20 split was used on a joined dataframe containing hospital general information and hospital characteristic variables.  All data was obtained from the Center for Medicare and Medicaid Services' (CMS) website.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r import, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
pacman::p_load(tidyverse, caret, MASS, cvms, kableExtra)
```

```{r readFiles, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
star_ratings <- read_csv("data/Hospital_General_Information.csv")
hospital_characteristics <- read_csv("data/Provider_of_Services_File_Hospital_Non_Hospital_Facilities_Dataset_2020_Q4.csv")
```

```{r wrangleData, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
hospitals <- star_ratings %>%
  filter(`Hospital Type` == "Acute Care Hospitals") %>%
  dplyr::select(c("Facility ID", "Facility Name", 
                  "Emergency Services", 
                  "Hospital overall rating")) %>%
  rename(Facility.ID = "Facility ID") %>%
  rename(star_rating = "Hospital overall rating") %>%
  mutate(star_rating = as.numeric(star_rating)) %>%
  na.omit()

characteristics <- hospital_characteristics %>%
  dplyr::select(c("PRVDR_NUM", "CBSA_URBN_RRL_IND", "ACRDTN_TYPE_CD",
                  "CRTFD_BED_CNT", "MDCL_SCHL_AFLTN_CD", "OPRTG_ROOM_CNT", 
                  "CRNA_CNT", "LPN_LVN_CNT", "DIETN_CNT", "LAB_TCHNCN_CNT", 
                  "NRS_PRCTNR_CNT", "PHYSN_CNT", "REG_PHRMCST_CNT", 
                  "NUCLR_MDCN_TCHNCN_CNT", "TOT_AFLTD_ESRD_CNT", "TOT_AFLTD_HHA_CNT", 
                  "TOT_AFLTD_SNF_CNT", "GNRL_CNTL_TYPE_CD")) %>%
  rename(Facility.ID = "PRVDR_NUM") %>%
  mutate(ACRDTN_TYPE_CD = as.character(ACRDTN_TYPE_CD)) %>%
  mutate(MDCL_SCHL_AFLTN_CD = as.character(MDCL_SCHL_AFLTN_CD))

char_and_rate <- left_join(hospitals, characteristics, by = "Facility.ID")

#recategorize ownership type variable with sparse data for some categories
char_and_rate <- char_and_rate %>%
  mutate(star_rating = as.factor(star_rating)) %>%
  mutate(GNRL_CNTL_TYPE_CD = case_when(GNRL_CNTL_TYPE_CD == "01" ~ "Private_NFP", 
                                       GNRL_CNTL_TYPE_CD == "02" ~ "Private_NFP", 
                                       GNRL_CNTL_TYPE_CD == "05" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "06" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "07" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "10" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "03" ~ "Other", 
                                       GNRL_CNTL_TYPE_CD == "08" ~ "Other", 
                                       GNRL_CNTL_TYPE_CD == "09" ~ "Other", 
                                       TRUE ~ "Private_FP")) %>%
  mutate(ACRDTN_TYPE_CD = case_when(ACRDTN_TYPE_CD == "2" ~ "1", 
                                    ACRDTN_TYPE_CD == "3" ~ "1", 
                                    ACRDTN_TYPE_CD == "9" ~ "1", 
                                    TRUE ~ "0")) %>%
  mutate(MDCL_SCHL_AFLTN_CD = case_when(MDCL_SCHL_AFLTN_CD == "2" ~ "1", 
                                        MDCL_SCHL_AFLTN_CD == "3" ~ "1", 
                                        MDCL_SCHL_AFLTN_CD == "4" ~ "0", 
                                        TRUE ~ "1"))  %>%
  rename(Emergency_Services = `Emergency Services`, Accredited = ACRDTN_TYPE_CD,
         Urban_Rural_Indicator = CBSA_URBN_RRL_IND, Certified_Bed_Count = CRTFD_BED_CNT, 
         Med_School_Affiliated = MDCL_SCHL_AFLTN_CD, Operating_Room_Count = OPRTG_ROOM_CNT,
         CRNA_Count = CRNA_CNT, LPN_LVN_Count = LPN_LVN_CNT, Dietician_Count = DIETN_CNT,
         Lab_Tech_Count = LAB_TCHNCN_CNT, Nurse_Practitioner_Count = NRS_PRCTNR_CNT,
         Physician_Count = PHYSN_CNT, Registered_Pharmacist_Count = REG_PHRMCST_CNT,
         Nuclear_Med_Tech_Count = NUCLR_MDCN_TCHNCN_CNT, Total_Affiliated_ESRD_Count = TOT_AFLTD_ESRD_CNT,
         Total_Affiliated_HHC_Count = TOT_AFLTD_HHA_CNT, Total_Affiliated_SNF_Count = TOT_AFLTD_SNF_CNT,
         Ownership_Type = GNRL_CNTL_TYPE_CD)
```

```{r setSeed, echo = FALSE, warning = FALSE, erorr = FALSE}
set.seed(123)
```

```{r regressionData, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
training_data <- char_and_rate %>%
  dplyr::select(c(-"Facility.ID", -"Facility Name")) %>%
  sample_frac(.80)

training_data_actual <- training_data %>%
  dplyr::select(c("star_rating"))

#testing data - predict on 20% of the data
testing_data <- anti_join(char_and_rate, training_data)

testing_data_actual <- testing_data %>%
  dplyr::select(c("star_rating"))

testing_data <- testing_data %>%
  dplyr::select(c(-"Facility.ID", -"star_rating", -"Facility Name"))
```

\

### Ordinal Regression Summary Table\

The following table is a summary of the ordinal logistic regression model results.  The p-value was calculated using the t-values determined by the model.  Based on a p value < 0.5, the significant variables are: Certified bed count, Medical school affiliation(y/n), LPN/LVN count, Nuclear medicine technician count, and Ownership type.  The following are interpretations of the coefficients of 'Certified bed count' and 'Ownership type':

* Certified bed count - For every unit increase in certified bed count, we expect the odds of a higher star rating to change by .999, given all other variables in the model are held constant. 
* Ownership type - When ownership type changes from 'Government' to 'Other', we expect the odds of a higher star rating to change by 2.0, given all other variables in the model are held constant. Additionally, when ownership changes from 'Government' to 'Priviate Not-for-profit', we expect the odds of a higher star rating to change by 2.77 given all other variables in the model are held constant.\

```{r regressionModel, echo = TRUE, warning = FALSE, error = FALSE}
#run regression model on training data
model_fit <- polr(star_rating~., data = training_data, Hess = TRUE)

summary_table <- coef(summary(model_fit))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval, 3))
summary_table <- as.data.frame(summary_table)

summary_table <- summary_table %>%
  rename(Coefficients = Value) %>%
  mutate(Odds.ratio = exp(Coefficients)) %>%
  slice(1:20)

summary_table <- subset(summary_table, select = c(1, 5, 2, 3, 4)) 

summary_table %>%
  kbl(digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = T, position = "center", html_font = "Calibri", font_size = 16) %>%
  column_spec(6, background = ifelse(summary_table$`p value`[1:20] < 0.05, "lightgreen", "white"))
```

\

## Confusion Matrix - Testing Accuracy of Prediction\

The random 20% testing data was used to predict star ratings from the ordinal regression model. A prediction matrix was calculated using the "predict" function, which generated a matrix of predictions for each value of the ordinal variable (star ratings).  To test the accuracy of prediction, a confusion matrix was generated using the actual star ratings for each hospital as the actual class and the max predicted star rating from the testing data as the predicted class. 

Result: The confusion matrix suggested an overall accuracy of 32.2%, and a balanced accuracy was 51.6%.  To test for possible overfitting, a re-prediction was performed on the 80% data used to train the regression model.  The confusion matrix results suggested an accuracy of 34.7% and a balanced accuracy of 53.7%.  This result indicates underfitting.

Conclusion: The overall and balanced prediction accuracy are low.  These variables are not sufficient to predict hospital quality with a high accuracy.  The model does show some ability to predict 3 & 4 star hospitals (as shown in the confusion matrix), and perhaps the model can be tuned further using variables from other sources.     

```{r testRegression, echo = FALSE, warning = FALSE, error = FALSE}
#predict star ratings using the model and testing data
prediction_testing <- round(predict(model_fit, testing_data, type = "p"), 3)
prediction_testing <- as.data.frame(prediction_testing) 
  
prediction_testing$prediction_testing_max <- pmax(prediction_testing$`1`, 
                                  prediction_testing$`2`, 
                                  prediction_testing$`3`, 
                                  prediction_testing$`4`, 
                                  prediction_testing$`5`)
prediction_testing$predicted_class <- NA

prediction_testing_class <- prediction_testing %>%
  mutate(predicted_class = as.factor(ifelse(prediction_testing_max == `4`, "4", 
                                   ifelse(prediction_testing_max == `3`, "3",
                                          ifelse(prediction_testing_max == `2`, "2",
                                                 ifelse(prediction_testing_max == `1`, "1", "5"))))))


prediction_testing_class$predicted_class <- factor(prediction_testing_class$predicted_class, 
                                           levels = c("1", "2", "3", "4", "5"))

#predict star ratings using the model and training data
prediction_training <- round(predict(model_fit, training_data, type = "p"), 3)
prediction_training <- as.data.frame(prediction_training) 
  
prediction_training$prediction_training_max <- pmax(prediction_training$`1`, 
                                  prediction_training$`2`, 
                                  prediction_training$`3`, 
                                  prediction_training$`4`, 
                                  prediction_training$`5`)
prediction_training$predicted_class <- NA

prediction_training_class <- prediction_training %>%
  mutate(predicted_class = as.factor(ifelse(prediction_training_max == `4`, "4", 
                                   ifelse(prediction_training_max == `3`, "3",
                                          ifelse(prediction_training_max == `2`, "2",
                                                 ifelse(prediction_training_max == `1`, "1", "5"))))))


prediction_training_class$predicted_class <- factor(prediction_training_class$predicted_class, 
                                           levels = c("1", "2", "3", "4", "5"))
```

```{r plotCM_Code, echo = TRUE, warning = FALSE, error = FALSE, fig.show = "hide"}
cm_testing <-  confusion_matrix(as.factor(testing_data_actual$star_rating), 
                        as.factor(prediction_testing_class$predicted_class))

plot_confusion_matrix(cm_testing$`Confusion Matrix`[[1]], 
                      place_x_axis_above = FALSE, 
                      palette = "Greens",
                      add_row_percentages = FALSE, 
                      add_col_percentages = FALSE) +
  labs(title = "Star Ratings prediction on testing data", 
       subtitle = "Overall Accuracy: 32.2%, Balanced Accuracy: 51.6%")
```

```{r plotCM_testing, echo = FALSE, warning = FALSE, error = FALSE, fig.show = "hold", out.width="100%"}
cm_testing <-  confusion_matrix(as.factor(testing_data_actual$star_rating), 
                        as.factor(prediction_testing_class$predicted_class))

plot_confusion_matrix(cm_testing$`Confusion Matrix`[[1]], 
                      place_x_axis_above = FALSE, 
                      palette = "Greens",
                      add_row_percentages = FALSE, 
                      add_col_percentages = FALSE) +
  labs(title = "Star Ratings prediction on testing data", 
       subtitle = "Overall Accuracy: 32.2%, Balanced Accuracy: 51.6%")
```

\

```{r plotCM_training, echo = FALSE, warning = FALSE, error = FALSE, fig.show = "hold", out.width="100%"}
cm_training <- confusion_matrix(as.factor(training_data_actual$star_rating), 
                        as.factor(prediction_training_class$predicted_class))

plot_confusion_matrix(cm_training$`Confusion Matrix`[[1]], 
                      place_x_axis_above = FALSE, 
                      palette = "Greens",
                      add_row_percentages = FALSE, 
                      add_col_percentages = FALSE) +
  labs(title = "Star Ratings prediction on training data", 
       subtitle = "Overall Accuracy: 34.7%, Balanced Accuracy: 53.3%")
```