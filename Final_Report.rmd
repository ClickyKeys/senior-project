---
title: "Analysis of Acute Care Hospital Quality"
author: "Lori Nichols"
output:
  pdf_document: default
  html_document: default
---

<style type="text/css">
h1.title {
  color: DarkBlue;
  text-align: center;
}

h4.author {
  color: DarkBlue;
  text-align: center;
}
</style>

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r import, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
pacman::p_load(tidyverse, rlist, skimr, caret, MASS, cvms, kableExtra, VIM, sjPlot, factoextra, NbClust, cluster, rgl, fossil)
```

```{r readInitial, echo = FALSE}
#cluster <- read_csv("data/Measures_by_Hospital_Acute_Care_New.csv")
```

\

# Part 1 - Exploratory Clustering Analysis of Hospital Quality Measures

The aim of this analysis is to explore how the Center for Medicare and Medicaid Services (CMS) uses quality measure data to determine overall hospital quality. To achieve this, a popular statistical technique will be used, K-means clustering.  K-means partitions observations into a pre-defined number of groups (or clusters) based on similarities between variables.  Using this method, we can identify natural groupings in hospitals based on a variety of quality measures.  The resulting clusters can then be compared to CMS's overall star ratings to determine if they are useful for determining hospital quality as indicated by CMS's star rating system. 



## Normalize the data

The dataset being used for this analysis contains numerous variables, which are measured and scaled differently.  The clustering method being used uses k-means, which is a distance-based algorithm.  It is important to bring all variables to the same scale, otherwise variables measured in large valued units will dominate the computed dissimilarity and vars measured in small valued units will contribute very little. 

The normalization method being used is min-max normalization (or min-max scaling), which normalizes the values on a scale of 0 - 1, where 0 is the min value and 1 is the max,
all other data points fall between those two values./

```{r normalize, echo = TRUE, warning = FALSE, error = FALSE, message = FALSE}
# normalize <- function(x) {
#   return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
# }
# 
# for(i in 2:length(cluster)) {
#   cluster[i] <- normalize(cluster[i])
# }
```



## Impute missing values using kNN imputation

The dataset being used for this analysis has missing values, which need to be removed or imputed prior to running the k-means algorithm.  The imputation method used is imputation with kNN, which looks at values that are close in space and imputes the mean value of the k nearest neighbors, where k is the sqrt of the total number of observations.

```{r impute, echo = TRUE, warning = FALSE, error = FALSE, message = FALSE}
# kVal = floor(sqrt(nrow(cluster)))
# cluster_NAR <- cluster %>%
#   kNN(variable = 2:length(cluster), k = kVal, imp_var = FALSE)
```

```{r write, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
# write_csv(cluster_NAR, "data/cluster_normalized.csv")
```

```{r seed, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
set.seed(123)
```



## Selecting variables for k-means clustering

Observing the dataset, there are 64 quality measure score variables.  The measure scores appear to fall into two categories: Preliminary scores which account for a single measure (ie. Readmission for COPD), and summary scores, which summarize multiple, preliminary variables (ie. summary of all Readmission measures).  The data has been separated into 3 data frames, which will be explored separate with k-means clustering and the results compared:

* All measure scores (preliminary + summary)
* Preliminary scores only
* Summary scores only

```{r readData_All, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
cluster_norm <- read_csv("data/cluster_normalized.csv")

cluster_norm_vars <- cluster_norm %>%
  dplyr::select(c(-"Facility.ID"))
```

```{r readData_All_Raw, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
cluster_norm_vars_raw <- cluster_norm %>%
  dplyr::select(c(-"Facility.ID", -"Total.Performance.Score", -"Weighted.Efficiency.and.Cost.Reduction.Domain.Score", -"Unweighted.Normalized.Efficiency.and.Cost.Reduction.Domain.Score", -"Weighted.Person.and.Community.Engagement.Domain.Score", -"Unweighted.Person.and.Community.Engagement.Domain.Score", -"Weighted.Normalized.Clinical.Outcomes.Domain.Score", -"HCAHPS.Consistency.Score", -"HCAHPS.Base.Score", -"Overall.Rating.of.Hospital.Dimension.Score", -"Discharge.Information.Dimension.Score", -"Cleanliness.and.Quietness.of.Hospital.Environment.Dimension.Score", -"Communication.About.Medicines.Dimension.Score", -"Care.Transition.Dimension.Score", -"Responsiveness.of.Hospital.Staff.Dimension.Score", -"Communication.with.Doctors.Dimension.Score", -"Communication.with.Nurses.Dimension.Score", -"H_STAR_RATING.x"))
```

```{r readData_All_Summary, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
cluster_norm_vars_summary <- cluster_norm %>%
  dplyr::select(c(-"Facility.ID")) %>%
  dplyr::select(c("Total.Performance.Score", "Weighted.Efficiency.and.Cost.Reduction.Domain.Score", "Unweighted.Normalized.Efficiency.and.Cost.Reduction.Domain.Score", "Weighted.Person.and.Community.Engagement.Domain.Score", "Unweighted.Person.and.Community.Engagement.Domain.Score", "Weighted.Normalized.Clinical.Outcomes.Domain.Score", "HCAHPS.Consistency.Score", "HCAHPS.Base.Score", "Overall.Rating.of.Hospital.Dimension.Score", "Discharge.Information.Dimension.Score", "Cleanliness.and.Quietness.of.Hospital.Environment.Dimension.Score", "Communication.About.Medicines.Dimension.Score", "Care.Transition.Dimension.Score", "Responsiveness.of.Hospital.Staff.Dimension.Score", "Communication.with.Doctors.Dimension.Score", "Communication.with.Nurses.Dimension.Score", "H_STAR_RATING.x"))
```



### Calculate the Rand Index for various values of 'k'

To determine if the clustering captures hospital quality (as defined by CMS), the Rand Index (RI) algorithm can be used. RI is a similarity computation method which accepts two clusters.  For the purpose of this analysis, one cluster will be the results of the k-means clustering algorithm, and one cluster will be the overall star rating determined by CMS.  The rand index algorithm outputs a value between 0 and 1, where 0 indicates no similarity and 1 indicates perfect similarity between clusters.  The output is adjusted (adjusted RI) to account for random chance groupings of elements.  

The adjusted RI was calculated for clusters (k) ranging from 2 - 8 and displayed on a bar graph.  

*Results:* For all 3 measure score datasets, the adjusted RI indicates low similarity for all k clusters.  Although there is a significant increase in the ARI when 'k' > 6, the value is < 0.5, indicating a low similarity between clusters.  Interestingly, comparing star ratings to the dataset containing only summary measure scores resulted in the lowest ARI for all k clusters.

*Conclusion:* The computed clusters may be useful, but we can conclude they can not be used to indicate quality as defined by CMS's star ratings.  CMS likely uses different methodology go determine their overall star ratings.

```{r RandIndex_function, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
RI <- function(x, y, z) {
  km4 <- kmeans(y, centers = x, nstart = 55)
  fviz_cluster(km4, data = y, ellipse.type = c("norm"), geom = "point", palette = "Set1", ggtheme = theme_minimal())
  
  #Add cluster results to original data frame
  cluster_results <- as.data.frame(km4$cluster)
  hosp_clusters <- bind_cols(cluster_norm, cluster_results)
  
  #glimpse(cluster_results)
  #glimpse(hosp_clusters)
    
  hosp_clusters <- hosp_clusters %>%
    dplyr::select(c("Facility.ID", "km4$cluster")) %>%
    rename(cluster = `km4$cluster`) %>%
    transform(Facility.ID = as.character(Facility.ID))
  #glimpse(hosp_clusters)
    
  #compare clustering results of ground truth overall star ratings
  star_ratings <- read_csv("data/Hospital_General_Information.csv")
  
  star_ratings <- star_ratings %>%
    filter(`Hospital Type` == "Acute Care Hospitals") %>%
    dplyr::select(c("Facility ID", "Hospital overall rating")) %>%
    rename(Facility.ID = `Facility ID`) %>%
    rename(Star.Rating = `Hospital overall rating`) %>%
    transform(Star.Rating = as.numeric(Star.Rating))
    
  star_ratings$Facility.ID <- star_ratings$Facility.ID %>%
    trimws("left", "0")
  #glimpse(star_ratings)
    
  hosp_cluster_comparison <- full_join(hosp_clusters, star_ratings)
  #glimpse(hosp_cluster_comparison)
    
  clust_analysis <- hosp_cluster_comparison %>%
    group_by(cluster, Star.Rating) %>%
    count()
  #glimpse(clust_analysis)
    
  clust_analysis %>%
    ggplot() +
    geom_bar(mapping = aes(x = Star.Rating, y = n, fill = cluster), stat = "identity") +
    facet_wrap(~ cluster)
    
  #Use rand index to comparison compare clustering accuracy
  hosp_clust_comp <- hosp_cluster_comparison %>%
    na.omit()
  #glimpse(hosp_clust_comp)
    
  adj.rand.index(hosp_clust_comp$Star.Rating,  hosp_clust_comp$cluster)
}
```



### Adjusted Rand Index for all quality measure scores in the data table

```{r k-meansAll_RandIndex1, echo = TRUE, warning = FALSE, error = FALSE, message = FALSE}
kVal <- NULL
randIndex <- NULL

for(i in 2:8) {
  kVal <- list.append(kVal, i)
  randIndex <- list.append(randIndex, RI(i, cluster_norm_vars))
}

randIndexResults <- tibble(kVal = as.character(kVal), randIndex)

randIndexResults %>%
  ggplot() +
  geom_bar(mapping = aes(x = kVal, y = randIndex, fill = kVal), 
           stat = "identity", 
           position = "dodge") +
  scale_fill_brewer(palette = "RdPu", aesthetics = "fill")
```

### Adjusted Rand Index for all quality measure scores minus summary scores

```{r k-meansAll_RandIndex2, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
kVal <- NULL
randIndex <- NULL

for(i in 2:8) {
  kVal <- list.append(kVal, i)
  randIndex <- list.append(randIndex, RI(i, cluster_norm_vars_raw))
}

randIndexResults <- tibble(kVal = as.character(kVal), randIndex)

randIndexResults %>%
  ggplot() +
  geom_bar(mapping = aes(x = kVal, y = randIndex, fill = kVal), stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "RdPu", aesthetics = "fill")

#Low randIndex, these clusters may be useful but not an indicator of quality as defined by CMS's star ratings
#CMS uses different methodology go determine their final star ratings
```

### Adjusted Rand Index for quality measure summary scores only

```{r k-meansAll_RandIndex3, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
kVal <- NULL
randIndex <- NULL

for(i in 2:8) {
  kVal <- list.append(kVal, i)
  randIndex <- list.append(randIndex, RI(i, cluster_norm_vars_summary))
}

randIndexResults <- tibble(kVal = as.character(kVal), randIndex)

randIndexResults %>%
  ggplot() +
  geom_bar(mapping = aes(x = kVal, y = randIndex, fill = kVal), stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "RdPu", aesthetics = "fill")

#Low randIndex, these clusters may be useful but not an indicator of quality as defined by CMS's star ratings
#CMS uses different methodology go determine their final star ratings
```



### K-means Clustering visualizations

The K-means clusters used in the adjusted RI index are visualized below on a scatterplot.  The values shown are 4 and 8, which showed fairly significant differences in similarity to the clusters implied by CMS's star ratings.  Notably, the dimensions shown on the x-axis and y-axis are dimensions generated through Principle Component Analysis (PCA) - a dimensionality reduction algorithm - that account for most of the variation in the original dataset.  Considering the original dataset has high dimensionality, there may be distinct clusters that are not visually distinct on this 2d projection.    

*Results:* For the clustering using all measures, there appears to be some significant clustering behavior, and the algorithm has done a fairly good job of capturing the clusters. However, a common issue with k-means clustering is apparent.  K-means assumes spherical clusters and therefore has difficulty capturing elongated clusters.  There appear to be multiple distinct, elongated clusters present that the algorithm has difficulty capturing for a low number of clusters k. /

```{r k-meansAll_Clusters, fig.show = "hold", out.width = "50%", echo = TRUE, message = FALSE, warning = FALSE}
clustering <- function(x, y, z) {
  km4 <- kmeans(y, centers = x, nstart = 55)
  fviz_cluster(km4, data = y, ellipse.type = c("norm"), 
               geom = "point", 
               ggtheme = theme_minimal()) +
    scale_fill_brewer(palette = "rainbow") +
    labs(title = z)
}

#For all measures in data frame
clustering(4, cluster_norm_vars, "4 Clusters - All Measures")
clustering(8, cluster_norm_vars, "8 Clusters - All Measures")

#For quality measure scores minus summary scores
clustering(4, cluster_norm_vars_raw, "4 Clusters - No Summary Scores")
clustering(8, cluster_norm_vars_raw, "8 Clusters - No Summary Scores")

#For summary quality measure scores only
clustering(4, cluster_norm_vars_summary, "4 Clusters - Summary Scores")
clustering(8, cluster_norm_vars_summary, "4 Clusters - Summary Scores")
```



# Part 2 - Predicting Hospital Quality Using Hospital Characteristic Data

The aim of this analysis is to determine if hospital star ratings can be predicted using several hospital characteristic-related variables.  To achieve this, ordinal logistic regression was used to model the relationship between star ratings (the ordinal response variable) and hospital characteristics (the explanatory variables).  The 80/20 split was used on a joined dataframe containing hospital general information and hospital characteristic variables.  All data was obtained from the Center for Medicare and Medicaid Services' (CMS) website.  

```{r readFiles, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
star_ratings <- read_csv("data/Hospital_General_Information.csv")
hospital_characteristics <- read_csv("data/Provider_of_Services_File_Hospital_Non_Hospital_Facilities_Dataset_2020_Q4.csv")
```

```{r wrangleData, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE}
hospitals <- star_ratings %>%
  filter(`Hospital Type` == "Acute Care Hospitals") %>%
  dplyr::select(c("Facility ID", "Facility Name", 
                  "Emergency Services", 
                  "Hospital overall rating")) %>%
  rename(Facility.ID = "Facility ID") %>%
  rename(star_rating = "Hospital overall rating") %>%
  mutate(star_rating = as.numeric(star_rating)) %>%
  na.omit()

characteristics <- hospital_characteristics %>%
  dplyr::select(c("PRVDR_NUM", "CBSA_URBN_RRL_IND", "ACRDTN_TYPE_CD",
                  "CRTFD_BED_CNT", "MDCL_SCHL_AFLTN_CD", "OPRTG_ROOM_CNT", 
                  "CRNA_CNT", "LPN_LVN_CNT", "DIETN_CNT", "LAB_TCHNCN_CNT", 
                  "NRS_PRCTNR_CNT", "PHYSN_CNT", "REG_PHRMCST_CNT", 
                  "NUCLR_MDCN_TCHNCN_CNT", "TOT_AFLTD_ESRD_CNT", "TOT_AFLTD_HHA_CNT", 
                  "TOT_AFLTD_SNF_CNT", "GNRL_CNTL_TYPE_CD")) %>%
  rename(Facility.ID = "PRVDR_NUM") %>%
  mutate(ACRDTN_TYPE_CD = as.character(ACRDTN_TYPE_CD)) %>%
  mutate(MDCL_SCHL_AFLTN_CD = as.character(MDCL_SCHL_AFLTN_CD))

char_and_rate <- left_join(hospitals, characteristics, by = "Facility.ID")

#recategorize ownership type variable with sparse data for some categories
char_and_rate <- char_and_rate %>%
  mutate(star_rating = as.factor(star_rating)) %>%
  mutate(GNRL_CNTL_TYPE_CD = case_when(GNRL_CNTL_TYPE_CD == "01" ~ "Private_NFP", 
                                       GNRL_CNTL_TYPE_CD == "02" ~ "Private_NFP", 
                                       GNRL_CNTL_TYPE_CD == "05" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "06" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "07" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "10" ~ "Government", 
                                       GNRL_CNTL_TYPE_CD == "03" ~ "Other", 
                                       GNRL_CNTL_TYPE_CD == "08" ~ "Other", 
                                       GNRL_CNTL_TYPE_CD == "09" ~ "Other", 
                                       TRUE ~ "Private_FP")) %>%
  mutate(ACRDTN_TYPE_CD = case_when(ACRDTN_TYPE_CD == "2" ~ "1", 
                                    ACRDTN_TYPE_CD == "3" ~ "1", 
                                    ACRDTN_TYPE_CD == "9" ~ "1", 
                                    TRUE ~ "0")) %>%
  mutate(MDCL_SCHL_AFLTN_CD = case_when(MDCL_SCHL_AFLTN_CD == "2" ~ "1", 
                                        MDCL_SCHL_AFLTN_CD == "3" ~ "1", 
                                        MDCL_SCHL_AFLTN_CD == "4" ~ "0", 
                                        TRUE ~ "1"))  %>%
  rename(Emergency_Services = `Emergency Services`, Accredited = ACRDTN_TYPE_CD,
         Urban_Rural_Indicator = CBSA_URBN_RRL_IND, Certified_Bed_Count = CRTFD_BED_CNT, 
         Med_School_Affiliated = MDCL_SCHL_AFLTN_CD, Operating_Room_Count = OPRTG_ROOM_CNT,
         CRNA_Count = CRNA_CNT, LPN_LVN_Count = LPN_LVN_CNT, Dietician_Count = DIETN_CNT,
         Lab_Tech_Count = LAB_TCHNCN_CNT, Nurse_Practitioner_Count = NRS_PRCTNR_CNT,
         Physician_Count = PHYSN_CNT, Registered_Pharmacist_Count = REG_PHRMCST_CNT,
         Nuclear_Med_Tech_Count = NUCLR_MDCN_TCHNCN_CNT, Total_Affiliated_ESRD_Count = TOT_AFLTD_ESRD_CNT,
         Total_Affiliated_HHC_Count = TOT_AFLTD_HHA_CNT, Total_Affiliated_SNF_Count = TOT_AFLTD_SNF_CNT,
         Ownership_Type = GNRL_CNTL_TYPE_CD)
```

```{r setSeed, echo = FALSE, warning = FALSE, erorr = FALSE}
set.seed(123)
```

```{r regressionData, echo = TRUE, warning = FALSE, error = FALSE, message = FALSE}
training_data <- char_and_rate %>%
  dplyr::select(c(-"Facility.ID", -"Facility Name")) %>%
  sample_frac(.80)

training_data_actual <- training_data %>%
  dplyr::select(c("star_rating"))

#testing data - predict on 20% of the data
testing_data <- anti_join(char_and_rate, training_data)

testing_data_actual <- testing_data %>%
  dplyr::select(c("star_rating"))

testing_data <- testing_data %>%
  dplyr::select(c(-"Facility.ID", -"star_rating", -"Facility Name"))
```


## Ordinal Regression Summary Table

The following table is a summary of the ordinal logistic regression model results.  The p-value was calculated using the t-values determined by the model.  Based on a p value < 0.5, the significant variables are: Certified bed count, Medical school affiliation(y/n), LPN/LVN count, Nuclear medicine technician count, and Ownership type.  The following are interpretations of the coefficients of 'Certified bed count' and 'Ownership type':

* Certified bed count - For every unit increase in certified bed count, we expect the odds of a higher star rating to change by .999, given all other variables in the model are held constant. 
* Ownership type - When ownership type changes from 'Government' to 'Other', we expect the odds of a higher star rating to change by 2.0, given all other variables in the model are held constant. Additionally, when ownership changes from 'Government' to 'Priviate Not-for-profit', we expect the odds of a higher star rating to change by 2.77 given all other variables in the model are held constant.

```{r regressionModel, echo = TRUE, warning = FALSE, error = FALSE}
#run regression model on training data
model_fit <- polr(star_rating~., data = training_data, Hess = TRUE)

summary_table <- coef(summary(model_fit))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval, 3))
summary_table <- as.data.frame(summary_table)

summary_table <- summary_table %>%
  mutate(Variables = rownames(summary_table)) %>%
  rename(Coefficients = Value) %>%
  mutate(Odds.ratio = exp(Coefficients)) %>%
  slice(1:20)

rownames(summary_table) <- NULL
glimpse(summary_table)

summary_table <- subset(summary_table, select = c(5, 1, 6, 2, 3, 4)) 

summary_table %>%
  kbl(digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = T, 
                position = "center", 
                html_font = "Calibri") %>%
  column_spec(6, background = ifelse(summary_table$`p value`[1:20] < 0.05, 
                                  "lightgreen", 
                                  "white"))
```


## Confusion Matrix - Testing Accuracy of Prediction

The random 20% testing data was used to predict star ratings from the ordinal regression model. A prediction matrix was calculated using the "predict" function, which generated a matrix of predictions for each value of the ordinal variable (star ratings).  To test the accuracy of prediction, a confusion matrix was generated using the actual star ratings for each hospital as the actual class and the max predicted star rating from the testing data as the predicted class. 

Result: The confusion matrix suggested an overall accuracy of 32.2%, and a balanced accuracy was 51.6%.  To test for possible overfitting, a re-prediction was performed on the 80% data used to train the regression model.  The confusion matrix results suggested an accuracy of 34.7% and a balanced accuracy of 53.7%.  This result indicates underfitting.

Conclusion: The overall and balanced prediction accuracy are low.  These variables are not sufficient to predict hospital quality with a high accuracy.  The model does show some ability to predict 3 & 4 star hospitals (as shown in the confusion matrix), and perhaps the model can be tuned further using variables from other sources.     

```{r testRegression, echo = FALSE, warning = FALSE, error = FALSE}
#predict star ratings using the model and testing data
prediction_testing <- round(predict(model_fit, testing_data, type = "p"), 3)
prediction_testing <- as.data.frame(prediction_testing) 
  
prediction_testing$prediction_testing_max <- pmax(prediction_testing$`1`, 
                                  prediction_testing$`2`, 
                                  prediction_testing$`3`, 
                                  prediction_testing$`4`, 
                                  prediction_testing$`5`)
prediction_testing$predicted_class <- NA

prediction_testing_class <- prediction_testing %>%
  mutate(predicted_class = as.factor(ifelse(prediction_testing_max == `4`, "4", 
                                   ifelse(prediction_testing_max == `3`, "3",
                                          ifelse(prediction_testing_max == `2`, "2",
                                                 ifelse(prediction_testing_max == `1`, "1", "5"))))))


prediction_testing_class$predicted_class <- factor(prediction_testing_class$predicted_class, 
                                           levels = c("1", "2", "3", "4", "5"))

#predict star ratings using the model and training data
prediction_training <- round(predict(model_fit, training_data, type = "p"), 3)
prediction_training <- as.data.frame(prediction_training) 
  
prediction_training$prediction_training_max <- pmax(prediction_training$`1`, 
                                  prediction_training$`2`, 
                                  prediction_training$`3`, 
                                  prediction_training$`4`, 
                                  prediction_training$`5`)
prediction_training$predicted_class <- NA

prediction_training_class <- prediction_training %>%
  mutate(predicted_class = as.factor(ifelse(prediction_training_max == `4`, "4", 
                                   ifelse(prediction_training_max == `3`, "3",
                                          ifelse(prediction_training_max == `2`, "2",
                                                 ifelse(prediction_training_max == `1`, "1", "5"))))))


prediction_training_class$predicted_class <- factor(prediction_training_class$predicted_class, 
                                           levels = c("1", "2", "3", "4", "5"))
```

```{r plotCM_Code, echo = TRUE, warning = FALSE, error = FALSE, fig.show = "hide"}
cm_testing <-  confusion_matrix(as.factor(testing_data_actual$star_rating), 
                        as.factor(prediction_testing_class$predicted_class))

plot_confusion_matrix(cm_testing$`Confusion Matrix`[[1]], 
                      place_x_axis_above = FALSE, 
                      palette = "Greens",
                      add_row_percentages = FALSE, 
                      add_col_percentages = FALSE) +
  labs(title = "Star Ratings prediction on testing data", 
       subtitle = "Overall Accuracy: 32.2%, Balanced Accuracy: 51.6%")
```

```{r plotCM_testing, echo = FALSE, warning = FALSE, error = FALSE, fig.show = "hold", out.width="100%"}
cm_testing <-  confusion_matrix(as.factor(testing_data_actual$star_rating), 
                        as.factor(prediction_testing_class$predicted_class))

plot_confusion_matrix(cm_testing$`Confusion Matrix`[[1]], 
                      place_x_axis_above = FALSE, 
                      palette = "Greens",
                      add_row_percentages = FALSE, 
                      add_col_percentages = FALSE) +
  labs(title = "Star Ratings prediction on testing data", 
       subtitle = "Overall Accuracy: 32.2%, Balanced Accuracy: 51.6%")
```


```{r plotCM_training, echo = FALSE, warning = FALSE, error = FALSE, fig.show = "hold", out.width="100%"}
cm_training <- confusion_matrix(as.factor(training_data_actual$star_rating), 
                        as.factor(prediction_training_class$predicted_class))

plot_confusion_matrix(cm_training$`Confusion Matrix`[[1]], 
                      place_x_axis_above = FALSE, 
                      palette = "Greens",
                      add_row_percentages = FALSE, 
                      add_col_percentages = FALSE) +
  labs(title = "Star Ratings prediction on training data", 
       subtitle = "Overall Accuracy: 34.7%, Balanced Accuracy: 53.3%")
```

# Part 3 - Regional Variations in Hospital Quality

Click the following link to use the Acute Care Hospital Finder app:

[Acute Care Hospital Finder](https://444-information-visualization.shinyapps.io/Acute_Care_Hospital_Finder/)
